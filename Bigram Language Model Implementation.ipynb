{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "44924388-6b6d-4f6c-bec3-d4d517dee2a3",
      "cell_type": "code",
      "source": "from collections import defaultdict\n\n# -----------------------------\n# 1. Training Corpus\n# -----------------------------\ncorpus = [\n    \"<s> I love NLP </s>\",\n    \"<s> I love deep learning </s>\",\n    \"<s> deep learning is fun </s>\"\n]\n\n# -----------------------------\n# 2. Compute Unigram & Bigram Counts\n# -----------------------------\nunigram_counts = defaultdict(int)\nbigram_counts = defaultdict(int)\n\nfor sentence in corpus:\n    words = sentence.split()\n    for i in range(len(words)):\n        unigram_counts[words[i]] += 1\n        if i < len(words) - 1:\n            bigram = (words[i], words[i+1])\n            bigram_counts[bigram] += 1\n\nprint(\"Unigram Counts:\")\nfor word, count in unigram_counts.items():\n    print(f\"{word}: {count}\")\n\nprint(\"\\nBigram Counts:\")\nfor bigram, count in bigram_counts.items():\n    print(f\"{bigram}: {count}\")\n\n# -----------------------------\n# 3. Bigram Probability (MLE)\n# -----------------------------\ndef bigram_prob(w1, w2):\n    if unigram_counts[w1] == 0:\n        return 0\n    return bigram_counts[(w1, w2)] / unigram_counts[w1]\n\n# -----------------------------\n# 4. Sentence Probability Function\n# -----------------------------\ndef sentence_probability(sentence):\n    words = sentence.split()\n    prob = 1.0\n    for i in range(len(words) - 1):\n        prob *= bigram_prob(words[i], words[i+1])\n    return prob\n\n# -----------------------------\n# 5. Test Sentences\n# -----------------------------\ns1 = \"<s> I love NLP </s>\"\ns2 = \"<s> I love deep learning </s>\"\n\np1 = sentence_probability(s1)\np2 = sentence_probability(s2)\n\nprint(\"\\nSentence Probabilities:\")\nprint(f\"P(S1) = {p1:.4f}\")\nprint(f\"P(S2) = {p2:.4f}\")\n\n# -----------------------------\n# 6. Model Preference\n# -----------------------------\nif p1 > p2:\n    print(\"\\nModel prefers S1 because it has higher probability.\")\nelif p2 > p1:\n    print(\"\\nModel prefers S2 because it has higher probability.\")\nelse:\n    print(\"\\nBoth sentences have equal probability.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Unigram Counts:\n<s>: 3\nI: 2\nlove: 2\nNLP: 1\n</s>: 3\ndeep: 2\nlearning: 2\nis: 1\nfun: 1\n\nBigram Counts:\n('<s>', 'I'): 2\n('I', 'love'): 2\n('love', 'NLP'): 1\n('NLP', '</s>'): 1\n('love', 'deep'): 1\n('deep', 'learning'): 2\n('learning', '</s>'): 1\n('<s>', 'deep'): 1\n('learning', 'is'): 1\n('is', 'fun'): 1\n('fun', '</s>'): 1\n\nSentence Probabilities:\nP(S1) = 0.3333\nP(S2) = 0.1667\n\nModel prefers S1 because it has higher probability.\n"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "55710941-d492-4933-a2d2-2a98c1c64953",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}